{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import merging\n",
    "import preprocess\n",
    "import scores\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load new file\n",
    "df = pd.read_csv('df_preprocessed_2015-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Flight Datetime', 'AOBT', 'ATOT']\n",
    "for col in cols:\n",
    "    df[col] = pd.to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Flight Datetime', 'AOBT', 'ATOT'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special characters from variable names\n",
    "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "df.drop(['Unnamed0','AircraftModel_x', 'Stand', 'Runway', 'summary', 'Manufacturer',\n",
    "       'Model', 'WakeCategory', 'Final', 'AircraftModel_y', 'OldMovementType'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['aobt_month', 'aobt_day', 'aobt_hour']\n",
    "for col in cols:\n",
    "    df[col]=df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess.ohe(df,['aobt_month','aobt_hour','aobt_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_var = ['flight_hour','flight_weekday','cloudCover','windSpeed','windBearing','traffic', 'Q',\n",
    "        'TO1', 'TO2', 'TO3',  'TORunway1',\n",
    "       'TORunway2', 'TORunway3',\n",
    "       'aobt_year', 'aobt_month_1', 'aobt_month_2',\n",
    "       'aobt_month_3', 'aobt_month_4', 'aobt_month_5', 'aobt_month_6',\n",
    "       'aobt_month_7', 'aobt_month_8', 'aobt_month_9', 'aobt_month_10',\n",
    "       'aobt_month_11', 'aobt_month_12', 'aobt_hour_0', 'aobt_hour_1',\n",
    "       'aobt_hour_2', 'aobt_hour_3', 'aobt_hour_4', 'aobt_hour_5',\n",
    "       'aobt_hour_6', 'aobt_hour_7', 'aobt_hour_8', 'aobt_hour_9',\n",
    "       'aobt_hour_10', 'aobt_hour_11', 'aobt_hour_12', 'aobt_hour_13',\n",
    "       'aobt_hour_14', 'aobt_hour_15', 'aobt_hour_16', 'aobt_hour_17',\n",
    "       'aobt_hour_18', 'aobt_hour_19', 'aobt_hour_20', 'aobt_hour_21',\n",
    "       'aobt_hour_22', 'aobt_hour_23', 'aobt_day_0', 'aobt_day_1',\n",
    "       'aobt_day_2', 'aobt_day_3', 'aobt_day_4', 'aobt_day_5', 'aobt_day_6',\n",
    "       'precipAccumulation',   'Lengthft','TO']\n",
    "df_lightGBM = df[features_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(df):\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_ ]+', '', x))\n",
    "    train=df[df['aobt_year']!=2019]\n",
    "    test=df[df['aobt_year']==2019]\n",
    "    X_train=train.drop('TO',axis=1)\n",
    "    X_test=test.drop('TO',axis=1)\n",
    "    y_train=train['TO']\n",
    "    y_test=test['TO']\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial, fast_check=True, target_meter=0, return_info=False):\n",
    "    folds = 5\n",
    "    seed = 666\n",
    "    shuffle = False\n",
    "    kf = model_selection.KFold(n_splits=folds, shuffle=shuffle, random_state=seed)\n",
    "    \n",
    "    X_train,y_train,X_test,y_test = create_train_test(df_lightGBM)\n",
    "    \n",
    "    y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "\n",
    "    models = []\n",
    "    valid_score = 0\n",
    "    for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "        train_data = X_train.iloc[train_idx,:], y_train.iloc[train_idx]\n",
    "        valid_data = X_train.iloc[valid_idx,:], y_train.iloc[valid_idx]\n",
    "\n",
    "        print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "        model, y_pred_valid, log = fit_lgbm(trial, train_data, valid_data,num_rounds=1000) \n",
    "                                            \n",
    "        y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "        models.append(model)\n",
    "        valid_score += log[\"valid/l2\"]\n",
    "        if fast_check:\n",
    "            break\n",
    "    valid_score /= len(models)\n",
    "    if return_info:\n",
    "        return valid_score, models, y_pred_valid, y_train\n",
    "    else:\n",
    "        return valid_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(trial, train, val, devices=(-1,), seed=None, cat_features=None, num_rounds=1500):\n",
    "    \"\"\"Train Light GBM model\"\"\"\n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = val\n",
    "    metric = 'l2'\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'objective': 'regression',\n",
    "#               'max_depth': -1,\n",
    "        'learning_rate': 0.1,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        \"bagging_freq\": 5,\n",
    "        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        \"metric\": metric,\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    device = devices[0]\n",
    "    if device == -1:\n",
    "        # use cpu\n",
    "        pass\n",
    "    else:\n",
    "        # use gpu\n",
    "        print(f'using gpu device_id {device}...')\n",
    "        params.update({'device': 'gpu', 'gpu_device_id': device})\n",
    "\n",
    "    params['seed'] = seed\n",
    "\n",
    "    early_stop = 20\n",
    "    verbose_eval = 20\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)\n",
    "    watchlist = [d_train, d_valid]\n",
    "\n",
    "    print('training LGB:')\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval,\n",
    "                      early_stopping_rounds=early_stop)\n",
    "\n",
    "    # predictions\n",
    "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    \n",
    "    print('best_score', model.best_score)\n",
    "    log = {'train/l2': model.best_score['training']['l2'],\n",
    "           'valid/l2': model.best_score['valid_1']['l2']}\n",
    "    return model, y_pred_valid, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:09:15,388] A new study created in memory with name: no-name-b17fad60-6909-41c6-8fd8-9e51caede5eb\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 189027\tvalid_1's l2: 167926\n",
      "[40]\ttraining's l2: 184099\tvalid_1's l2: 163284\n",
      "[60]\ttraining's l2: 182462\tvalid_1's l2: 162008\n",
      "[80]\ttraining's l2: 181626\tvalid_1's l2: 161511\n",
      "[100]\ttraining's l2: 181010\tvalid_1's l2: 161124\n",
      "[120]\ttraining's l2: 180593\tvalid_1's l2: 160968\n",
      "[140]\ttraining's l2: 180221\tvalid_1's l2: 160859\n",
      "[160]\ttraining's l2: 179814\tvalid_1's l2: 160780\n",
      "[180]\ttraining's l2: 179441\tvalid_1's l2: 160691\n",
      "[200]\ttraining's l2: 179116\tvalid_1's l2: 160603\n",
      "[220]\ttraining's l2: 178797\tvalid_1's l2: 160566\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttraining's l2: 178872\tvalid_1's l2: 160539\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 178872.3772212358)]), 'valid_1': OrderedDict([('l2', 160538.93583405932)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:09:26,172] Trial 0 finished with value: 160538.93583405932 and parameters: {'num_leaves': 13, 'lambda_l1': 0.0950974134553322, 'lambda_l2': 0.18423816547058833, 'bagging_fraction': 0.40067438403946143, 'feature_fraction': 0.4129784003250001}. Best is trial 0 with value: 160538.93583405932.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 179664\tvalid_1's l2: 163577\n",
      "[40]\ttraining's l2: 172208\tvalid_1's l2: 160806\n",
      "[60]\ttraining's l2: 167238\tvalid_1's l2: 159832\n",
      "[80]\ttraining's l2: 163833\tvalid_1's l2: 159576\n",
      "[100]\ttraining's l2: 160918\tvalid_1's l2: 159330\n",
      "[120]\ttraining's l2: 158206\tvalid_1's l2: 159236\n",
      "[140]\ttraining's l2: 155753\tvalid_1's l2: 159140\n",
      "[160]\ttraining's l2: 153281\tvalid_1's l2: 158991\n",
      "[180]\ttraining's l2: 151267\tvalid_1's l2: 158901\n",
      "[200]\ttraining's l2: 149335\tvalid_1's l2: 158950\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's l2: 150352\tvalid_1's l2: 158880\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 150351.63865899766)]), 'valid_1': OrderedDict([('l2', 158879.63328458526)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:09:53,779] Trial 1 finished with value: 158879.63328458526 and parameters: {'num_leaves': 166, 'lambda_l1': 8.05868866329061e-08, 'lambda_l2': 0.01653533616154787, 'bagging_fraction': 0.6646506053400946, 'feature_fraction': 0.7896426302626525}. Best is trial 1 with value: 158879.63328458526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 179484\tvalid_1's l2: 163743\n",
      "[40]\ttraining's l2: 171708\tvalid_1's l2: 160653\n",
      "[60]\ttraining's l2: 166627\tvalid_1's l2: 159918\n",
      "[80]\ttraining's l2: 163009\tvalid_1's l2: 159637\n",
      "[100]\ttraining's l2: 159766\tvalid_1's l2: 159514\n",
      "[120]\ttraining's l2: 156884\tvalid_1's l2: 159581\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's l2: 159412\tvalid_1's l2: 159473\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 159411.76325349574)]), 'valid_1': OrderedDict([('l2', 159472.7296134298)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:10:20,938] Trial 2 finished with value: 159472.7296134298 and parameters: {'num_leaves': 219, 'lambda_l1': 1.1027592302417265e-07, 'lambda_l2': 1.3909909107875533e-05, 'bagging_fraction': 0.4675775476590517, 'feature_fraction': 0.6315956055266557}. Best is trial 1 with value: 158879.63328458526.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 183745\tvalid_1's l2: 164232\n",
      "[40]\ttraining's l2: 178359\tvalid_1's l2: 160814\n",
      "[60]\ttraining's l2: 175327\tvalid_1's l2: 159774\n",
      "[80]\ttraining's l2: 173259\tvalid_1's l2: 159325\n",
      "[100]\ttraining's l2: 171698\tvalid_1's l2: 158955\n",
      "[120]\ttraining's l2: 170190\tvalid_1's l2: 158749\n",
      "[140]\ttraining's l2: 168864\tvalid_1's l2: 158539\n",
      "[160]\ttraining's l2: 167568\tvalid_1's l2: 158338\n",
      "[180]\ttraining's l2: 166417\tvalid_1's l2: 158193\n",
      "[200]\ttraining's l2: 165326\tvalid_1's l2: 158042\n",
      "[220]\ttraining's l2: 164209\tvalid_1's l2: 157958\n",
      "[240]\ttraining's l2: 163137\tvalid_1's l2: 157902\n",
      "[260]\ttraining's l2: 162088\tvalid_1's l2: 157823\n",
      "[280]\ttraining's l2: 160964\tvalid_1's l2: 157743\n",
      "[300]\ttraining's l2: 159948\tvalid_1's l2: 157681\n",
      "[320]\ttraining's l2: 158858\tvalid_1's l2: 157578\n",
      "[340]\ttraining's l2: 157926\tvalid_1's l2: 157483\n",
      "[360]\ttraining's l2: 156916\tvalid_1's l2: 157457\n",
      "[380]\ttraining's l2: 156079\tvalid_1's l2: 157381\n",
      "[400]\ttraining's l2: 155243\tvalid_1's l2: 157303\n",
      "[420]\ttraining's l2: 154419\tvalid_1's l2: 157242\n",
      "[440]\ttraining's l2: 153592\tvalid_1's l2: 157244\n",
      "Early stopping, best iteration is:\n",
      "[427]\ttraining's l2: 154130\tvalid_1's l2: 157208\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 154130.09924363493)]), 'valid_1': OrderedDict([('l2', 157208.2454841379)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:11:01,965] Trial 3 finished with value: 157208.2454841379 and parameters: {'num_leaves': 67, 'lambda_l1': 1.0034340430533997, 'lambda_l2': 6.273266822048027, 'bagging_fraction': 0.9441048263180452, 'feature_fraction': 0.7741800625243584}. Best is trial 3 with value: 157208.2454841379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 180635\tvalid_1's l2: 165089\n",
      "[40]\ttraining's l2: 171972\tvalid_1's l2: 161073\n",
      "[60]\ttraining's l2: 166805\tvalid_1's l2: 160135\n",
      "[80]\ttraining's l2: 162863\tvalid_1's l2: 159940\n",
      "[100]\ttraining's l2: 159484\tvalid_1's l2: 159952\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's l2: 161411\tvalid_1's l2: 159844\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 161410.5713909665)]), 'valid_1': OrderedDict([('l2', 159843.84958591513)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:11:17,934] Trial 4 finished with value: 159843.84958591513 and parameters: {'num_leaves': 248, 'lambda_l1': 0.17610495706218532, 'lambda_l2': 2.5109871580421584e-05, 'bagging_fraction': 0.4848740602653556, 'feature_fraction': 0.4681727404526955}. Best is trial 3 with value: 157208.2454841379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 184634\tvalid_1's l2: 164746\n",
      "[40]\ttraining's l2: 179536\tvalid_1's l2: 161247\n",
      "[60]\ttraining's l2: 177086\tvalid_1's l2: 160230\n",
      "[80]\ttraining's l2: 175406\tvalid_1's l2: 159754\n",
      "[100]\ttraining's l2: 174011\tvalid_1's l2: 159506\n",
      "[120]\ttraining's l2: 172708\tvalid_1's l2: 159378\n",
      "[140]\ttraining's l2: 171702\tvalid_1's l2: 159297\n",
      "[160]\ttraining's l2: 170551\tvalid_1's l2: 159145\n",
      "[180]\ttraining's l2: 169503\tvalid_1's l2: 159061\n",
      "[200]\ttraining's l2: 168585\tvalid_1's l2: 159040\n",
      "[220]\ttraining's l2: 167680\tvalid_1's l2: 158934\n",
      "[240]\ttraining's l2: 166723\tvalid_1's l2: 158940\n",
      "[260]\ttraining's l2: 165918\tvalid_1's l2: 158862\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's l2: 166103\tvalid_1's l2: 158837\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 166102.70436217808)]), 'valid_1': OrderedDict([('l2', 158837.26153437182)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:11:38,653] Trial 5 finished with value: 158837.26153437182 and parameters: {'num_leaves': 50, 'lambda_l1': 1.986473985560066, 'lambda_l2': 1.2512121971823337e-06, 'bagging_fraction': 0.6631345865246341, 'feature_fraction': 0.6069137138167517}. Best is trial 3 with value: 157208.2454841379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 183704\tvalid_1's l2: 165185\n",
      "[40]\ttraining's l2: 177126\tvalid_1's l2: 161139\n",
      "[60]\ttraining's l2: 173713\tvalid_1's l2: 160160\n",
      "[80]\ttraining's l2: 171203\tvalid_1's l2: 159674\n",
      "[100]\ttraining's l2: 168894\tvalid_1's l2: 159413\n",
      "[120]\ttraining's l2: 167041\tvalid_1's l2: 159246\n",
      "[140]\ttraining's l2: 165475\tvalid_1's l2: 159086\n",
      "[160]\ttraining's l2: 163937\tvalid_1's l2: 158931\n",
      "[180]\ttraining's l2: 162547\tvalid_1's l2: 158883\n",
      "[200]\ttraining's l2: 161162\tvalid_1's l2: 158847\n",
      "[220]\ttraining's l2: 159703\tvalid_1's l2: 158792\n",
      "[240]\ttraining's l2: 158441\tvalid_1's l2: 158684\n",
      "[260]\ttraining's l2: 157279\tvalid_1's l2: 158509\n",
      "[280]\ttraining's l2: 156095\tvalid_1's l2: 158503\n",
      "[300]\ttraining's l2: 154936\tvalid_1's l2: 158443\n",
      "[320]\ttraining's l2: 153740\tvalid_1's l2: 158448\n",
      "Early stopping, best iteration is:\n",
      "[301]\ttraining's l2: 154872\tvalid_1's l2: 158431\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 154871.94644128619)]), 'valid_1': OrderedDict([('l2', 158431.36699270862)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:12:06,342] Trial 6 finished with value: 158431.36699270862 and parameters: {'num_leaves': 101, 'lambda_l1': 9.09282953743888e-08, 'lambda_l2': 1.5840166087287617, 'bagging_fraction': 0.7275757935403158, 'feature_fraction': 0.49965218490455243}. Best is trial 3 with value: 157208.2454841379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 179751\tvalid_1's l2: 163842\n",
      "[40]\ttraining's l2: 172692\tvalid_1's l2: 162102\n",
      "[60]\ttraining's l2: 167938\tvalid_1's l2: 161876\n",
      "[80]\ttraining's l2: 164450\tvalid_1's l2: 161977\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's l2: 167325\tvalid_1's l2: 161820\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 167325.06404465047)]), 'valid_1': OrderedDict([('l2', 161820.36003140526)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:12:21,060] Trial 7 finished with value: 161820.36003140526 and parameters: {'num_leaves': 249, 'lambda_l1': 0.009726573140172322, 'lambda_l2': 0.028273591813719103, 'bagging_fraction': 0.25821292511459376, 'feature_fraction': 0.8084095954374562}. Best is trial 3 with value: 157208.2454841379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 183471\tvalid_1's l2: 164402\n",
      "[40]\ttraining's l2: 178390\tvalid_1's l2: 161535\n",
      "[60]\ttraining's l2: 175658\tvalid_1's l2: 160845\n",
      "[80]\ttraining's l2: 173773\tvalid_1's l2: 160554\n",
      "[100]\ttraining's l2: 172206\tvalid_1's l2: 160352\n",
      "[120]\ttraining's l2: 170885\tvalid_1's l2: 160335\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's l2: 171300\tvalid_1's l2: 160283\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 171299.57839214543)]), 'valid_1': OrderedDict([('l2', 160282.90001383825)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:12:32,660] Trial 8 finished with value: 160282.90001383825 and parameters: {'num_leaves': 71, 'lambda_l1': 7.509068976635221e-07, 'lambda_l2': 3.065867424603642e-05, 'bagging_fraction': 0.3958660013536853, 'feature_fraction': 0.7867925122959177}. Best is trial 3 with value: 157208.2454841379.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 435048 valid 108763\n",
      "training LGB:\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's l2: 187834\tvalid_1's l2: 166630\n",
      "[40]\ttraining's l2: 183580\tvalid_1's l2: 162813\n",
      "[60]\ttraining's l2: 182055\tvalid_1's l2: 161766\n",
      "[80]\ttraining's l2: 181276\tvalid_1's l2: 161367\n",
      "[100]\ttraining's l2: 180656\tvalid_1's l2: 161101\n",
      "[120]\ttraining's l2: 180254\tvalid_1's l2: 160971\n",
      "[140]\ttraining's l2: 179850\tvalid_1's l2: 160913\n",
      "[160]\ttraining's l2: 179499\tvalid_1's l2: 160822\n",
      "[180]\ttraining's l2: 179185\tvalid_1's l2: 160816\n",
      "[200]\ttraining's l2: 178823\tvalid_1's l2: 160699\n",
      "[220]\ttraining's l2: 178414\tvalid_1's l2: 160651\n",
      "Early stopping, best iteration is:\n",
      "[213]\ttraining's l2: 178530\tvalid_1's l2: 160602\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('l2', 178530.21694196048)]), 'valid_1': OrderedDict([('l2', 160601.60062476317)])})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-10-08 12:12:45,569] Trial 9 finished with value: 160601.60062476317 and parameters: {'num_leaves': 13, 'lambda_l1': 0.0006440142119142004, 'lambda_l2': 1.3462347168821946, 'bagging_fraction': 0.36726729033819483, 'feature_fraction': 0.621796541410032}. Best is trial 3 with value: 157208.2454841379.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective,n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 157208.2454841379, params {'num_leaves': 67, 'lambda_l1': 1.0034340430533997, 'lambda_l2': 6.273266822048027, 'bagging_fraction': 0.9441048263180452, 'feature_fraction': 0.7741800625243584}\n"
     ]
    }
   ],
   "source": [
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 67, 'lambda_l1': 1.0034340430533997, 'lambda_l2': 6.273266822048027, 'bagging_fraction': 0.9441048263180452, 'feature_fraction': 0.7741800625243584,'n_jobs':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1800\n",
      "[LightGBM] [Info] Number of data points in the train set: 543811, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 1125.316185\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = create_train_test(df_lightGBM)\n",
    "train_set = lgb.Dataset(X_train, label=y_train)\n",
    "model = lgb.train(params,train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 430.290247\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
